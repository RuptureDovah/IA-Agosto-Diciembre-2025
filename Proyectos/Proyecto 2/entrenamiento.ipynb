{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079682ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando en: c:\\Users\\victo\\Desktop\\Tec\\Semestre9\\IA\\dataset\n",
      "Clases detectadas (5): ['ant', 'cat', 'dog', 'ladybug', 'turtle']\n",
      "Cargando imÃ¡genes (esto puede tardar)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\Desktop\\Tec\\Semestre9\\IA\\venv\\Lib\\site-packages\\PIL\\Image.py:1039: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "c:\\Users\\victo\\Desktop\\Tec\\Semestre9\\IA\\venv\\Lib\\site-packages\\PIL\\Image.py:1039: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "c:\\Users\\victo\\Desktop\\Tec\\Semestre9\\IA\\venv\\Lib\\site-packages\\PIL\\Image.py:1039: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ant: 7633 imÃ¡genes\n",
      "  cat: 8000 imÃ¡genes\n",
      "  dog: 8000 imÃ¡genes\n",
      "  ladybug: 8000 imÃ¡genes\n",
      "  turtle: 8000 imÃ¡genes\n",
      "Procesando datos...\n",
      "Datos listos: X=(39633, 64, 64, 3), y=(39633, 5)\n",
      "Configurando Data Augmentation...\n",
      "Entrenando modelo con imÃ¡genes dinÃ¡micas...\n",
      "Epoch 1/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 123ms/step - accuracy: 0.6645 - loss: 0.7997 - val_accuracy: 0.6825 - val_loss: 0.7944\n",
      "Epoch 2/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 105ms/step - accuracy: 0.7472 - loss: 0.6186 - val_accuracy: 0.7534 - val_loss: 0.6332\n",
      "Epoch 3/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 104ms/step - accuracy: 0.7732 - loss: 0.5620 - val_accuracy: 0.7565 - val_loss: 0.5991\n",
      "Epoch 4/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 103ms/step - accuracy: 0.7858 - loss: 0.5260 - val_accuracy: 0.7979 - val_loss: 0.5186\n",
      "Epoch 5/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 105ms/step - accuracy: 0.7988 - loss: 0.4965 - val_accuracy: 0.7919 - val_loss: 0.5728\n",
      "Epoch 6/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 103ms/step - accuracy: 0.8035 - loss: 0.4815 - val_accuracy: 0.7886 - val_loss: 0.5667\n",
      "Epoch 7/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 105ms/step - accuracy: 0.8085 - loss: 0.4677 - val_accuracy: 0.8074 - val_loss: 0.5311\n",
      "Epoch 8/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 104ms/step - accuracy: 0.8169 - loss: 0.4490 - val_accuracy: 0.8074 - val_loss: 0.5334\n",
      "Epoch 9/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 110ms/step - accuracy: 0.8261 - loss: 0.4393 - val_accuracy: 0.8336 - val_loss: 0.4304\n",
      "Epoch 10/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 106ms/step - accuracy: 0.8264 - loss: 0.4305 - val_accuracy: 0.8591 - val_loss: 0.3785\n",
      "Epoch 11/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 106ms/step - accuracy: 0.8303 - loss: 0.4281 - val_accuracy: 0.8125 - val_loss: 0.5273\n",
      "Epoch 12/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 104ms/step - accuracy: 0.8383 - loss: 0.4064 - val_accuracy: 0.8279 - val_loss: 0.4442\n",
      "Epoch 13/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 111ms/step - accuracy: 0.8401 - loss: 0.3998 - val_accuracy: 0.8655 - val_loss: 0.3351\n",
      "Epoch 14/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 104ms/step - accuracy: 0.8416 - loss: 0.3944 - val_accuracy: 0.8552 - val_loss: 0.3746\n",
      "Epoch 15/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 106ms/step - accuracy: 0.8494 - loss: 0.3802 - val_accuracy: 0.8629 - val_loss: 0.3456\n",
      "Epoch 16/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 105ms/step - accuracy: 0.8452 - loss: 0.3913 - val_accuracy: 0.8394 - val_loss: 0.4186\n",
      "Epoch 17/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 105ms/step - accuracy: 0.8514 - loss: 0.3756 - val_accuracy: 0.8641 - val_loss: 0.3570\n",
      "Epoch 18/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 105ms/step - accuracy: 0.8484 - loss: 0.3808 - val_accuracy: 0.8701 - val_loss: 0.3436\n",
      "Epoch 19/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 107ms/step - accuracy: 0.8538 - loss: 0.3711 - val_accuracy: 0.8335 - val_loss: 0.4742\n",
      "Epoch 20/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 108ms/step - accuracy: 0.8556 - loss: 0.3637 - val_accuracy: 0.8421 - val_loss: 0.4585\n",
      "Epoch 21/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 107ms/step - accuracy: 0.8570 - loss: 0.3615 - val_accuracy: 0.8438 - val_loss: 0.4322\n",
      "Epoch 22/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 106ms/step - accuracy: 0.8561 - loss: 0.3634 - val_accuracy: 0.8276 - val_loss: 0.4886\n",
      "Epoch 23/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 108ms/step - accuracy: 0.8594 - loss: 0.3556 - val_accuracy: 0.8715 - val_loss: 0.3299\n",
      "Epoch 24/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 106ms/step - accuracy: 0.8609 - loss: 0.3519 - val_accuracy: 0.8697 - val_loss: 0.3424\n",
      "Epoch 25/25\n",
      "\u001b[1m991/991\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 107ms/step - accuracy: 0.8614 - loss: 0.3549 - val_accuracy: 0.8641 - val_loss: 0.3646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â¡Ã‰xito Total! Modelo guardado como 'modelo_animales.h5'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU, Input\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# --- CONFIGURACIÃ“N ---\n",
    "DIRECTORIO_DATASET = os.path.abspath(\"./dataset\")\n",
    "ANCHO = 64\n",
    "ALTO = 64\n",
    "CANALES = 3\n",
    "\n",
    "print(f\"Buscando en: {DIRECTORIO_DATASET}\")\n",
    "\n",
    "if not os.path.exists(DIRECTORIO_DATASET):\n",
    "    print(\"ERROR: No encuentro la carpeta 'dataset'.\")\n",
    "else:\n",
    "    # 1. DETECTAR CLASES\n",
    "    clases_validas = [\n",
    "        d for d in os.listdir(DIRECTORIO_DATASET)\n",
    "        if os.path.isdir(os.path.join(DIRECTORIO_DATASET, d))\n",
    "    ]\n",
    "    clases_validas.sort()\n",
    "\n",
    "    mapa_clases = {nombre: i for i, nombre in enumerate(clases_validas)}\n",
    "\n",
    "    print(f\"Clases detectadas ({len(clases_validas)}): {clases_validas}\")\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # 2. CARGA DE IMÃGENES\n",
    "    print(\"Cargando imÃ¡genes (esto puede tardar)...\")\n",
    "\n",
    "    for nombre_clase in clases_validas:\n",
    "        ruta_clase = os.path.join(DIRECTORIO_DATASET, nombre_clase)\n",
    "        archivos = os.listdir(ruta_clase)\n",
    "        count = 0\n",
    "\n",
    "        for archivo in archivos:\n",
    "            if archivo.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')):\n",
    "                ruta_imagen = os.path.join(ruta_clase, archivo)\n",
    "\n",
    "                try:\n",
    "                    img = imread(ruta_imagen)\n",
    "\n",
    "                    if len(img.shape) == 3 and img.shape[2] == 4:\n",
    "                        img = img[:, :, :3]\n",
    "\n",
    "                    img_resized = resize(\n",
    "                        img, (ALTO, ANCHO),\n",
    "                        anti_aliasing=True,\n",
    "                        preserve_range=True\n",
    "                    )\n",
    "\n",
    "                    if img_resized.shape[-1] == 3:\n",
    "                        images.append(img_resized)\n",
    "                        labels.append(mapa_clases[nombre_clase])\n",
    "                        count += 1\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        print(f\"  {nombre_clase}: {count} imÃ¡genes\")\n",
    "\n",
    "    # 3. PROCESAMIENTO\n",
    "    print(\"Procesando datos...\")\n",
    "    X = np.array(images, dtype=np.float32) / 255.0\n",
    "    y = np.array(labels)\n",
    "\n",
    "    y_one_hot = to_categorical(y, num_classes=len(clases_validas))\n",
    "\n",
    "    print(f\"Datos listos: X={X.shape}, y={y_one_hot.shape}\")\n",
    "\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "        X, y_one_hot, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # 4. MODELO CNN\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(ALTO, ANCHO, CANALES)))\n",
    "\n",
    "    # ğŸ”¹ BLOQUE 1\n",
    "    model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "    model.add(LeakyReLU(negative_slope=0.1))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # ğŸ”¹ BLOQUE 2\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(LeakyReLU(negative_slope=0.1))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # ğŸ”¥ BLOQUE 3\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(LeakyReLU(negative_slope=0.1))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # ClasificaciÃ³n\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(negative_slope=0.1))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(len(clases_validas), activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # 5. DATA AUGMENTATION Y ENTRENAMIENTO\n",
    "    print(\"Configurando Data Augmentation...\")\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    print(\"Entrenando modelo con imÃ¡genes dinÃ¡micas...\")\n",
    "\n",
    "    history = model.fit(\n",
    "        datagen.flow(train_X, train_Y, batch_size=32),\n",
    "        epochs=25,\n",
    "        validation_data=(test_X, test_Y)\n",
    "    )\n",
    "\n",
    "    # 6. GUARDAR MODELO\n",
    "    model.save(\"modelo_animales.h5\")\n",
    "    np.save(\"clases.npy\", clases_validas)\n",
    "\n",
    "    print(\"Â¡Ã‰xito Total! Modelo guardado como 'modelo_animales.h5'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
